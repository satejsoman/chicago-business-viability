Starting pipeline lr-rf (26b35e3e-0dee-411e-99c5-fdbc5b19d027) at 2019-06-07 21:59:57.624314
Input data: /Users/satej/Documents/workspace/classwork/machine-learning/chicago-business-viability/data/joined_table.csv (SHA-256: d2cd198dc228aa11cee4245b41fcd001eafea7250263af0a20882e7ad6f2c9ca)
Pipeline library version: bfd9e39

Pipeline settings:
    summarize: False
    data_preprocessors: None
    feature_generators: [<function count_by_zip_year at 0x121bcd400>, <function make_dummy_vars at 0x121bcd510>]
    models: {'LogisticRegression-C0.001-penaltyl1-n_jobs-1': LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=-1, penalty='l1',
                   random_state=None, solver='warn', tol=0.0001, verbose=0,
                   warm_start=False), 'LogisticRegression-C0.001-penaltyl2-n_jobs-1': LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=-1, penalty='l2',
                   random_state=None, solver='warn', tol=0.0001, verbose=0,
                   warm_start=False), 'LogisticRegression-C0.01-penaltyl1-n_jobs-1': LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=-1, penalty='l1',
                   random_state=None, solver='warn', tol=0.0001, verbose=0,
                   warm_start=False), 'LogisticRegression-C0.01-penaltyl2-n_jobs-1': LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=-1, penalty='l2',
                   random_state=None, solver='warn', tol=0.0001, verbose=0,
                   warm_start=False), 'LogisticRegression-C0.1-penaltyl1-n_jobs-1': LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=-1, penalty='l1',
                   random_state=None, solver='warn', tol=0.0001, verbose=0,
                   warm_start=False), 'LogisticRegression-C0.1-penaltyl2-n_jobs-1': LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=-1, penalty='l2',
                   random_state=None, solver='warn', tol=0.0001, verbose=0,
                   warm_start=False), 'LogisticRegression-C1-penaltyl1-n_jobs-1': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=-1, penalty='l1',
                   random_state=None, solver='warn', tol=0.0001, verbose=0,
                   warm_start=False), 'LogisticRegression-C1-penaltyl2-n_jobs-1': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=-1, penalty='l2',
                   random_state=None, solver='warn', tol=0.0001, verbose=0,
                   warm_start=False), 'LogisticRegression-C10-penaltyl1-n_jobs-1': LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=-1, penalty='l1',
                   random_state=None, solver='warn', tol=0.0001, verbose=0,
                   warm_start=False), 'LogisticRegression-C10-penaltyl2-n_jobs-1': LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=-1, penalty='l2',
                   random_state=None, solver='warn', tol=0.0001, verbose=0,
                   warm_start=False), 'LogisticRegression-C100-penaltyl1-n_jobs-1': LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=-1, penalty='l1',
                   random_state=None, solver='warn', tol=0.0001, verbose=0,
                   warm_start=False), 'LogisticRegression-C100-penaltyl2-n_jobs-1': LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=-1, penalty='l2',
                   random_state=None, solver='warn', tol=0.0001, verbose=0,
                   warm_start=False), 'RandomForestClassifier-n_estimators10-max_depthNone-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=None, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,
                       oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators10-max_depth1-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=1, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,
                       oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators10-max_depth5-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=5, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,
                       oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators10-max_depth10-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=10, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,
                       oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators10-max_depth50-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=50, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,
                       oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators10-max_depth100-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=100, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,
                       oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators100-max_depthNone-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=None, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators100-max_depth1-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=1, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators100-max_depth5-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=5, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators100-max_depth10-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=10, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators100-max_depth50-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=50, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators100-max_depth100-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=100, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators200-max_depthNone-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=None, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=200,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators200-max_depth1-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=1, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=200,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators200-max_depth5-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=5, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=200,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators200-max_depth10-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=10, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=200,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators200-max_depth50-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=50, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=200,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators200-max_depth100-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=100, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=200,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators500-max_depthNone-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=None, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=500,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators500-max_depth1-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=1, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=500,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators500-max_depth5-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=5, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=500,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators500-max_depth10-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=10, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=500,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators500-max_depth50-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=50, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=500,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators500-max_depth100-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=100, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=500,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators1000-max_depthNone-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=None, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=1000,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators1000-max_depth1-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=1, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=1000,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators1000-max_depth5-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=5, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=1000,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators1000-max_depth10-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=10, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=1000,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators1000-max_depth50-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=50, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=1000,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False), 'RandomForestClassifier-n_estimators1000-max_depth100-n_jobs-1': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
                       max_depth=100, max_features='auto', max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=1000,
                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,
                       warm_start=False)}
    name: lr-rf
    output_root_dir: /Users/satej/Documents/workspace/classwork/machine-learning/chicago-business-viability/code/output

Loading data

Running transformations for cleaning
    Applying transformation (1/12): convert-LICENSE TERM EXPIRATION DATE-to-datetime 
    LICENSE TERM EXPIRATION DATE -> LICENSE TERM EXPIRATION DATE
    Applying transformation (2/12): convert-DATE ISSUED-to-datetime 
    DATE ISSUED -> DATE ISSUED
    Applying transformation (3/12): replace-missing-values-with-mean(medhhinc) 
    ['medhhinc'] -> medhhinc
    Applying transformation (4/12): replace-missing-values-with-mean(a35to64_share) 
    ['a35to64_share'] -> a35to64_share
    Applying transformation (5/12): replace-missing-values-with-mean(share_BA+) 
    ['share_BA+'] -> share_BA+
    Applying transformation (6/12): replace-missing-values-with-mean(total_pop) 
    ['total_pop'] -> total_pop
    Applying transformation (7/12): replace-missing-values-with-mean(metro_GDP) 
    ['metro_GDP'] -> metro_GDP
    Applying transformation (8/12): replace-missing-values-with-mean(Cook_U3_ann_avg) 
    ['Cook_U3_ann_avg'] -> Cook_U3_ann_avg
    Applying transformation (9/12): replace-missing-values-with-mean(num_sites) 
    ['num_sites'] -> num_sites
    Applying transformation (10/12): replace-missing-values-with-mean(in_ssa) 
    ['in_ssa'] -> in_ssa
    Applying transformation (11/12): replace-missing-values-with-mean(which_ssa) 
    ['which_ssa'] -> which_ssa
    Applying transformation (12/12): replace-missing-values-with-mean(num_renewals) 
    ['num_renewals'] -> num_renewals

    Creating 2 features on test-train set 1
    Creating 2 features on test-train set 2
    Creating 2 features on test-train set 3
    Creating 2 features on test-train set 4
    Creating 2 features on test-train set 5
    Creating 2 features on test-train set 6
    Creating 2 features on test-train set 1
    Creating 2 features on test-train set 2
    Creating 2 features on test-train set 3
    Creating 2 features on test-train set 4
    Creating 2 features on test-train set 5
    Creating 2 features on test-train set 6
    Balancing features for test-train set 1
    Balancing features for test-train set 2
    Balancing features for test-train set 3
    Balancing features for test-train set 4
    Balancing features for test-train set 5
    Balancing features for test-train set 6
Training models.
Features: ['JOIN_YEAR', 'CITY_PEOTONE', 'CITY_JANESVILLE', 'which_ssa_25.0', 'CITY_FORT WAYNE', 'CITY_NORRIDGE', 'CITY_SCHILLER PARK', 'CITY_ROCKFORD', 'CITY_GURNEE', 'CITY_CENTRAL STICKNEY', 'CITY_HILLSIDE', 'CITY_PHOENIX', 'CITY_URBANA', 'CITY_WINNETKA', 'CITY_CLARENDON HILLS', 'CITY_SOUTH BEND', 'share_BA+', 'CITY_LAKE VILLA', 'which_ssa_44.0', 'which_ssa_1.0', 'CITY_SPRINGFIELD', 'CITY_OAK FOREST', 'which_ssa_0.0', 'which_ssa_21.0', 'CITY_ROBBINS', 'which_ssa_60.0', 'which_ssa_7.0', 'which_ssa_22.0', 'Cook_U3_ann_avg', 'CITY_FOREST PARK', 'CITY_LAKE GENEVA', 'CITY_LIBERTYVILLE', 'CITY_CHICAGO RIDGE', 'CITY_NEW LENOX', 'CITY_PALATINE', 'which_ssa_56.0', 'STATE_TX', 'which_ssa_61.0', 'CITY_LOS ANGELES', 'num_not_renewed_zip', 'CITY_LA GRANGE PARK', 'CITY_WHEELING', 'CITY_RIVERSIDE', 'CITY_ALSIP', 'which_ssa_3.0', 'CITY_MERRILLVILLE', 'CITY_STREAMWOOD', 'num_renewals', 'which_ssa_34.0', 'CITY_BURBANK', 'CITY_AURORA', 'CITY_SCHAUMBURG', 'in_ssa', 'CITY_GRIFFITH', 'which_ssa_69.0', 'CITY_DOLTON', 'CITY_OAK PARK', 'which_ssa_5.0', 'which_ssa_14.0', 'CITY_ELMWOOD PARK', 'which_ssa_8.0', 'which_ssa_13.0', 'CITY_ST.  LOUIS', 'which_ssa_40.0', 'CITY_CARPENTERSVILLE', 'CITY_CICERO', 'CITY_LANSING', 'CITY_CALUMET CITY', 'CITY_SERENA', 'CITY_HAMPSHIRE', 'which_ssa_62.0', 'which_ssa_26.0', 'CITY_HARTFORD CITY', 'CITY_PARK CITY', 'CITY_PARK FOREST', 'a35to64_share', 'CITY_ELK GROVE VILLAGE', 'CITY_FORD HEIGHTS', 'CITY_STAMFORD', 'which_ssa_51.0', 'CITY_NEW YORK', 'CITY_WESTMONT', 'STATE_KS', 'which_ssa_16.0', 'CITY_MUNSTER', 'CITY_EVERGREEN PARK', 'CITY_NORTHBROOK', 'CITY_ROCKTON', 'STATE_IA', 'CITY_LYONS', 'CITY_DIXMOOR', 'STATE_WI', 'CITY_WEST CHICAGO', 'CITY_CALUMENT', 'CITY_RICHTON PARK', 'CITY_MCHENRY', 'CITY_DEERFIELD', 'STATE_CT', 'CITY_STONE PARK', 'CITY_EVANSTON', 'STATE_CA', 'which_ssa_24.0', 'CITY_HINSDALE', 'CITY_HAMMOND', 'CITY_STEGER', 'CITY_FLOSSMOOR', 'CITY_NEWTON', 'CITY_NAPERVILLE', 'which_ssa_32.0', 'which_ssa_33.0', 'CITY_BATAVIA', 'which_ssa_28.0', 'CITY_PROVO', 'CITY_SOUTH ELGIN', 'CITY_GLENDALE HEIGHTS', 'CITY_HOMEWOOD', 'CITY_MELROSE PARK', 'CITY_GRAYSLAKE', 'CITY_ITASCA', 'STATE_IN', 'STATE_OK', 'which_ssa_18.0', 'which_ssa_35.0', 'CITY_WESTCHESTER', 'STATE_IL', 'CITY_BELLWOOD', 'CITY_VILLA PARK', 'CITY_NILES', 'CITY_HAZEL CREST', 'CITY_EDMOND', 'STATE_NY', 'CITY_BENSENVILLE', 'CITY_MAYWOOD', 'CITY_NORTHLAKE', 'medhhinc', 'CITY_WILMETTE', 'which_ssa_17.0', 'CITY_ELGIN', 'CITY_MONEE', 'CITY_ARLINGTON', 'CITY_BELOIT', 'CITY_OAKBROOK', 'CITY_CRANDON', 'CITY_JOLIET', 'CITY_WAUKEGAN', 'which_ssa_52.0', 'CITY_HARWOOD HEIGHTS', 'which_ssa_55.0', 'CITY_WHEATON', 'which_ssa_23.0', 'CITY_NORTH RIVERSIDE', 'CITY_ARLINGTON HEIGHTS', 'CITY_MASON', 'CITY_MILWAUKEE', 'CITY_MINNEAPOLIS', 'CITY_ADDISON', 'CITY_CARY', 'CITY_PHILADELPHIA', 'CITY_INDIANAPOLIS', 'CITY_BROOKFIELD', 'CITY_LAKE FOREST', 'total_pop', 'CITY_BLUE ISLAND', 'CITY_FOREST VIEW', 'CITY_CAROL STREAM', 'CITY_RIVERDALE', 'STATE_PA', 'which_ssa_4.0', 'CITY_OAK BROOK', 'which_ssa_27.0', 'which_ssa_47.0', 'STATE_MT', 'CITY_SKOKIE', 'CITY_WHITING', 'which_ssa_2.0', 'CITY_LISLE', 'CITY_PARK RIDGE', 'CITY_WOOD DALE', 'CITY_STRATFORD', 'CITY_MADISON', 'CITY_GLENVIEW', 'which_ssa_48.0', 'STATE_MO', 'which_ssa_59.0', 'CITY_A', 'CITY_WICHITA', 'CITY_NORTH AURORA', 'CITY_GLENWOOD', 'CITY_ROLLING MEADOWS', 'CITY_TINLEY PARK', 'CITY_MOUNT PROSPECT', 'CITY_DES PLAINES', 'CITY_LINCOLNSHIRE', 'CITY_EAST CHICAGO', 'CITY_WILLOW SPRINGS', 'CITY_DOWNERS GROVE', 'which_ssa_39.0', 'which_ssa_31.0', 'CITY_BERWYN', 'which_ssa_29.0', 'CITY_VERNON HILLS', 'which_ssa_64.0', 'CITY_LAGRANGE', 'STATE_MA', 'CITY_GARY', 'CITY_LA GRANGE HIGHLANDS', 'CITY_MISSOULA', 'CITY_SOUTHBEND', 'CITY_HIGHLAND PARK', 'CITY_ST LOUIS', 'CITY_HYDE PARK', 'CITY_LINCOLNWOOD', 'which_ssa_10.0', 'which_ssa_19.0', 'which_ssa_38.0', 'CITY_LOCKPORT', 'CITY_BEDFORD PARK', 'CITY_HOFFMAN ESTATES', 'CITY_MORTON GROVE', 'CITY_CHICAGO HEIGHTS', 'which_ssa_43.0', 'metro_GDP', 'CITY_DECATUR', 'STATE_AZ', 'which_ssa_42.0', 'num_sites', 'CITY_TULSA', 'CITY_FAIRFIELD', 'which_ssa_7.734634469478777', 'which_ssa_63.0', 'CITY_ERIE', 'CITY_FREEPORT', 'which_ssa_41.0', 'which_ssa_49.0', 'STATE_UT', 'CITY_GLEN ELLYN', 'CITY_BURR RIDGE', 'CITY_ELMWOOD', 'CITY_BROADVIEW', 'CITY_DAVENPORT', 'which_ssa_45.0', 'CITY_LOMBARD', 'CITY_UNIVERSITY PARK', 'CITY_OVERLAND PARK', 'CITY_ALGONQUIN', 'CITY_DARIEN', 'CITY_MCCOOK', 'CITY_ELMHURST', 'CITY_CHESTER', 'CITY_WILLOWBROOK', 'CITY_SUMMIT', 'which_ssa_20.0', 'CITY_ROSELLE', 'which_ssa_50.0', 'CITY_ROUND LAKE PARK', 'CITY_DALLAS', 'CITY_ELK GROVE', 'CITY_MANTENO', 'CITY_RIVER FOREST', 'STATE_MN', 'CITY_OAK LAWN', 'CITY_ROSEMONT', 'CITY_CHICAGO', 'CITY_LAKE BLUFF', 'CITY_FRANKLIN PARK', 'STATE_OH', 'which_ssa_54.0', 'CITY_NORTH CANTON']
Fitting: not_renewed_2yrs
    Training model LogisticRegression-C0.001-penaltyl1-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model LogisticRegression-C0.001-penaltyl2-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model LogisticRegression-C0.01-penaltyl1-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model LogisticRegression-C0.01-penaltyl2-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model LogisticRegression-C0.1-penaltyl1-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model LogisticRegression-C0.1-penaltyl2-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model LogisticRegression-C1-penaltyl1-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model LogisticRegression-C1-penaltyl2-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model LogisticRegression-C10-penaltyl1-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model LogisticRegression-C10-penaltyl2-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model LogisticRegression-C100-penaltyl1-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model LogisticRegression-C100-penaltyl2-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model RandomForestClassifier-n_estimators10-max_depthNone-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model RandomForestClassifier-n_estimators10-max_depth1-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model RandomForestClassifier-n_estimators10-max_depth5-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model RandomForestClassifier-n_estimators10-max_depth10-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model RandomForestClassifier-n_estimators10-max_depth50-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model RandomForestClassifier-n_estimators10-max_depth100-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model RandomForestClassifier-n_estimators100-max_depthNone-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model RandomForestClassifier-n_estimators100-max_depth1-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model RandomForestClassifier-n_estimators100-max_depth5-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model RandomForestClassifier-n_estimators100-max_depth10-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model RandomForestClassifier-n_estimators100-max_depth50-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model RandomForestClassifier-n_estimators100-max_depth100-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model RandomForestClassifier-n_estimators200-max_depthNone-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model RandomForestClassifier-n_estimators200-max_depth1-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model RandomForestClassifier-n_estimators200-max_depth5-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
        Training on training set "exists as of 12/31/2014" (3/6)
        Training on training set "exists as of 12/31/2015" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2017" (6/6)
    Training model RandomForestClassifier-n_estimators200-max_depth10-n_jobs-1
        Training on training set "exists as of 12/31/2012" (1/6)
        Training on training set "exists as of 12/31/2013" (2/6)
