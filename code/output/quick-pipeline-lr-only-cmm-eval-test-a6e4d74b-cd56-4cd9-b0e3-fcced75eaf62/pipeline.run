Starting pipeline quick-pipeline-lr-only-cmm-eval-test (a6e4d74b-cd56-4cd9-b0e3-fcced75eaf62) at 2019-06-05 22:16:31.162452
Input data: /Users/jonathantan/github/chicago-business-viability/data/joined_table_33pct_sample.csv (SHA-256: 0ed743805440e983cfef63ff265c5fd3935f5faf81e36aa21e3ca205654af628)
Pipeline library version: 6ceea78

Pipeline settings:
    summarize: True
    data_preprocessors: None
    feature_generators: [<function count_by_zip_year at 0x1225c5e18>]
    models: {'LogisticRegression-C0.01': LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='l2',
                   random_state=None, solver='warn', tol=0.0001, verbose=0,
                   warm_start=False), 'DecisionTreeClassifier-max_depthNone': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=None, splitter='best'), 'DecisionTreeClassifier-max_depth1': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=None, splitter='best'), 'DecisionTreeClassifier-max_depth5': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
                       max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort=False,
                       random_state=None, splitter='best')}
    name: quick-pipeline-lr-only-cmm-eval-test
    output_root_dir: /Users/jonathantan/github/chicago-business-viability/code/output

Loading data

Running transformations for cleaning
    Applying transformation (1/2): convert-LICENSE TERM EXPIRATION DATE-to-datetime 
    LICENSE TERM EXPIRATION DATE -> LICENSE TERM EXPIRATION DATE
    Applying transformation (2/2): convert-DATE ISSUED-to-datetime 
    DATE ISSUED -> DATE ISSUED

Summarizing data.
    Creating features on test-train set 1
    Creating features on test-train set 2
    Creating features on test-train set 3
    Creating features on test-train set 4
    Creating features on test-train set 5
    Creating features on test-train set 6
    Creating features on test-train set 1
    Creating features on test-train set 2
    Creating features on test-train set 3
    Creating features on test-train set 4
    Creating features on test-train set 5
    Creating features on test-train set 6
    Balancing features for test-train set 1
    Balancing features for test-train set 2
    Balancing features for test-train set 3
    Balancing features for test-train set 4
    Balancing features for test-train set 5
    Balancing features for test-train set 6
Training models.
Features: ['num_not_renewed_zip', 'not_renewed_2yrs']
Fitting: not_renewed_2yrs
    Training model LogisticRegression-C0.01
        Training on training set "exists as of 12/31/2008" (1/6)
        Training on training set "exists as of 12/31/2010" (2/6)
        Training on training set "exists as of 12/31/2012" (3/6)
        Training on training set "exists as of 12/31/2014" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2018" (6/6)
    Training model DecisionTreeClassifier-max_depthNone
        Training on training set "exists as of 12/31/2008" (1/6)
        Training on training set "exists as of 12/31/2010" (2/6)
        Training on training set "exists as of 12/31/2012" (3/6)
        Training on training set "exists as of 12/31/2014" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2018" (6/6)
    Training model DecisionTreeClassifier-max_depth1
        Training on training set "exists as of 12/31/2008" (1/6)
        Training on training set "exists as of 12/31/2010" (2/6)
        Training on training set "exists as of 12/31/2012" (3/6)
        Training on training set "exists as of 12/31/2014" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2018" (6/6)
    Training model DecisionTreeClassifier-max_depth5
        Training on training set "exists as of 12/31/2008" (1/6)
        Training on training set "exists as of 12/31/2010" (2/6)
        Training on training set "exists as of 12/31/2012" (3/6)
        Training on training set "exists as of 12/31/2014" (4/6)
        Training on training set "exists as of 12/31/2016" (5/6)
        Training on training set "exists as of 12/31/2018" (6/6)
Testing models.
    Evaluating model LogisticRegression-C0.01
        Evaluating on testing set "exists as of 12/31/2008" (1/6):
        Evaluating on testing set "exists as of 12/31/2010" (2/6):
        Evaluating on testing set "exists as of 12/31/2012" (3/6):
        Evaluating on testing set "exists as of 12/31/2014" (4/6):
        Evaluating on testing set "exists as of 12/31/2016" (5/6):
        Evaluating on testing set "exists as of 12/31/2018" (6/6):
