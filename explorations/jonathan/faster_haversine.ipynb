{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "\n",
    "# Tweak display settings for tables\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../data/Business_Licenses.csv\"\n",
    "DTYPE_DICT = {\n",
    "    'ZIP CODE': str,\n",
    "    'BUSINESS ACTIVITY ID': str,\n",
    "    'BUSINESS ACTIVITY': str,\n",
    "}\n",
    "DATE_COLS = ['LICENSE TERM EXPIRATION DATE', 'DATE ISSUED']\n",
    "\n",
    "license_df = pd.read_csv(DATA_PATH,\n",
    "                 dtype=DTYPE_DICT,\n",
    "                 parse_dates=DATE_COLS)\n",
    "license_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `get_locations()` and `reshape_and_make_label()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_locations(input_df):\n",
    "    '''\n",
    "    Takes license-level data and returns a dataframe with location attributes\n",
    "        for each account-site.\n",
    "    '''\n",
    "    # Columns to return\n",
    "    LOCATION_COLS = ['ACCOUNT NUMBER', 'SITE NUMBER', 'ADDRESS', 'CITY',\n",
    "                     'STATE', 'ZIP CODE', 'WARD', 'POLICE DISTRICT',\n",
    "                     'LATITUDE', 'LONGITUDE', 'LOCATION']\n",
    "\n",
    "    # Drop rows if these columns have NA\n",
    "    NA_COLS = ['LATITUDE', 'LONGITUDE', 'LOCATION']\n",
    "\n",
    "    df = input_df.copy(deep=True)[LOCATION_COLS] \\\n",
    "        .dropna(subset=NA_COLS) \\\n",
    "        .drop_duplicates() \\\n",
    "        .sort_values(by=['ACCOUNT NUMBER', 'SITE NUMBER'])\n",
    "\n",
    "    return df\n",
    "\n",
    "addresses = get_locations(df)\n",
    "\n",
    "addresses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_create_label(input_df):\n",
    "    '''\n",
    "    Processes raw business license-level dataframe into account-site-year level\n",
    "     dataframe. Extracts years from min/max year and expands dataframe into\n",
    "     account-site-year level.\n",
    "\n",
    "    Currently hardcoded to require columns for ACCOUNT NUMBER, SITE NUMBER,\n",
    "     DATE ISSUED, and LICENSE TERM EXPIRATION DATE\n",
    "\n",
    "    Input:  input_df - license-level dataframe\n",
    "    Output: result_df - business-year-level df with not_renewed_2yrs label\n",
    "    '''\n",
    "\n",
    "    # Aggregate by account-site and get min/max/expiry dates for licenses\n",
    "    df = input_df.copy(deep=True) \\\n",
    "        .groupby(['ACCOUNT NUMBER', 'SITE NUMBER']) \\\n",
    "        .agg({'DATE ISSUED': ['min', 'max'],\n",
    "              'LICENSE TERM EXPIRATION DATE': 'max'}) \\\n",
    "        .reset_index(col_level=1)\n",
    "\n",
    "    # Flatten column names into something usable\n",
    "    df.columns = df.columns.to_flat_index()\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        ('', 'ACCOUNT NUMBER'): \"account\",\n",
    "        ('' , 'SITE NUMBER'): 'site',\n",
    "        ('DATE ISSUED', 'min'): 'min_license_date',\n",
    "        ('DATE ISSUED', 'max'): 'max_license_date',\n",
    "        ('LICENSE TERM EXPIRATION DATE', 'max'): 'expiry'})\n",
    "\n",
    "    # Extract min/max license dates into list of years_open\n",
    "    df['years_open'] = pd.Series(map(lambda x, y: [z for z in range(x, y+2)],\n",
    "                                     df['min_license_date'].dt.year,\n",
    "                                     df['max_license_date'].dt.year))\n",
    "\n",
    "    # make account-site id var\n",
    "    # melt step below doesn't work well without merging these two cols\n",
    "    df['account_site'] = df['account'].astype('str') + \"-\" + df['site'].astype('str')\n",
    "    df = df[df.columns.tolist()[-1:] + df.columns.tolist()[:-1]]\n",
    "    df = df.drop(labels=['account', 'site'], axis=1)\n",
    "\n",
    "    # Expand list of years_open into one row for each account-site-year\n",
    "    # https://mikulskibartosz.name/how-to-split-a-list-inside-a-dataframe-cell-into-rows-in-pandas-9849d8ff2401\n",
    "    df = df \\\n",
    "        .years_open \\\n",
    "        .apply(pd.Series) \\\n",
    "        .merge(df, left_index=True, right_index=True) \\\n",
    "        .drop(labels=['years_open'], axis=1) \\\n",
    "        .melt(id_vars=['account_site', 'min_license_date', 'max_license_date',\n",
    "                       'expiry'],\n",
    "              value_name='YEAR') \\\n",
    "        .drop(labels=['variable'], axis=1) \\\n",
    "        .dropna() \\\n",
    "        .sort_values(by=['account_site', 'YEAR'])\n",
    "\n",
    "    # Split account_site back into ACCOUNT NUMBER, SITE NUMBER\n",
    "    df['ACCOUNT NUMBER'], df['SITE NUMBER'] = df['account_site'].str.split('-', 1).str\n",
    "    df['ACCOUNT NUMBER'] = df['ACCOUNT NUMBER'].astype('int')\n",
    "    df['SITE NUMBER'] = df['SITE NUMBER'].astype('int')\n",
    "\n",
    "    # reorder columns\n",
    "    df['YEAR'] = df['YEAR'].astype('int')\n",
    "    df = df[['ACCOUNT NUMBER', 'SITE NUMBER', 'account_site', 'YEAR',\n",
    "             'min_license_date', 'max_license_date', 'expiry']] \\\n",
    "        .sort_values(by=['ACCOUNT NUMBER', 'SITE NUMBER'])\n",
    "\n",
    "    # Assume buffer period is last 2 years of input data\n",
    "    threshold_year = input_df['DATE ISSUED'].dt.year.max() - 1\n",
    "    buffer_df = input_df.loc[input_df['DATE ISSUED'].dt.year >= threshold_year]\n",
    "\n",
    "    # Get list of account-site numbers in buffer\n",
    "    buffer_ids = buffer_df['ACCOUNT NUMBER'].astype('str') \\\n",
    "        + '-' + buffer_df['SITE NUMBER'].astype('str')\n",
    "\n",
    "    # Generate label\n",
    "    df['not_renewed_2yrs'] = np.where(df['expiry'].dt.year < threshold_year,\n",
    "        np.where(df['YEAR'] >= df['max_license_date'].dt.year + 1, 1, 0),\n",
    "        np.where(df['account_site'].isin(buffer_ids),\n",
    "            0,\n",
    "            np.where(df['YEAR'] >= df['max_license_date'].dt.year + 1, 1, 0)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    # Drop all years that we can't predict on, i.e. buffer years onwards\n",
    "    df = df.drop(labels=['account_site', 'min_license_date','max_license_date',\n",
    "                         'expiry'], axis=1) \\\n",
    "        .loc[df['YEAR'] < threshold_year] \\\n",
    "        .reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split this up into testing pd verses handcoded haversine:\n",
    "https://stackoverflow.com/questions/29545704/fast-haversine-approximation-python-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = get_locations(license_data)\n",
    "df = reshape_and_create_label(input_df) \\\n",
    "    .merge(addresses, how='left', on=['ACCOUNT NUMBER', 'SITE NUMBER'])\n",
    "\n",
    "# Select columns, transforms lat/long in degrees to radians\n",
    "df = df[['ACCOUNT NUMBER', 'SITE NUMBER', 'YEAR', 'LATITUDE', 'LONGITUDE',\n",
    "         'not_renewed_2yrs']]\n",
    "df['LATITUDE_rad'] = np.radians(df['LATITUDE'])\n",
    "df['LONGITUDE_rad'] = np.radians(df['LONGITUDE'])\n",
    "R = 6371 # circumference of the Earth in km\n",
    "\n",
    "year_dfs = []\n",
    "years = df['YEAR'].unique()\n",
    "\n",
    "for i in sorted(df['YEAR'].unique()):\n",
    "    year_df = df.loc[df['YEAR'] == i]\n",
    "    fails_only = year_df.loc[year_df['not_renewed_2yrs'] == 1]\n",
    "\n",
    "    # if no businesses failed that year, return a count of 0 for all\n",
    "    if len(fails_only) == 0:\n",
    "        year_df[0] = np.zeros(len(year_df)).astype('int')\n",
    "        year_df = year_df \\\n",
    "            .reset_index(drop=True) \\\n",
    "            .drop(labels=['LATITUDE', 'LONGITUDE', 'LATITUDE_rad',\n",
    "                          'LONGITUDE_rad', 'not_renewed_2yrs'], axis=1)\n",
    "    else:\n",
    "        # Get pairwise distance between all businesses that year and all\n",
    "        # nonrenewals that year. Then count number of nonrenewals within\n",
    "        # threshold distance (using row-wise sum) and join back on year_df\n",
    "        dist_df = R * haversine_distances(\n",
    "            year_df[['LATITUDE_rad', 'LONGITUDE_rad']],\n",
    "            fails_only[['LATITUDE_rad', 'LONGITUDE_rad']]\n",
    "        )\n",
    "        dist_df = pd.DataFrame(np.where(dist_df <= 1, 1, 0).sum(axis=1))\n",
    "        year_df = year_df \\\n",
    "            .reset_index(drop=True) \\\n",
    "            .join(dist_df) \\\n",
    "            .drop(labels=['LATITUDE', 'LONGITUDE', 'LATITUDE_rad',\n",
    "                          'LONGITUDE_rad', 'not_renewed_2yrs'], axis=1)\n",
    "\n",
    "    year_dfs.append(year_df)\n",
    "# Concatenate all year-specific dfs to get counts for all business-years\n",
    "# Then merge onto original df by business-year id cols\n",
    "all_years_df = pd.concat(year_dfs)\n",
    "results_df = input_df.merge(all_years_df,\n",
    "                            how='left',\n",
    "                            on=MERGE_KEYS) \\\n",
    "    .rename(columns={0: 'num_not_renewed_1km'}) \\\n",
    "    [['ACCOUNT NUMBER', 'SITE NUMBER', 'YEAR', 'num_not_renewed_1km' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
